{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The purpose of this exercise is to analyse the Economic trends and derive insights. To do this, the following steps will be taken:\n",
    "\n",
    "To achieve this, do the following\n",
    "1. Read each of the csv files iteratively\n",
    "2. Merge all of the data into a single dataframe by building a dictionary where the keys are the codes and the values are the Series from each downloaded file\n",
    "3. Construct the Term and Default premia series using basic math on the series, and merge the resulting series using JOIN operation. NOTE: term_premium = merged_data[’GS10’] - merged_data[’GS1’] and default_premium = merged_data[’BAA’] - merged_data[’AAA’]\n",
    "4. Process the data by treating the data for nulls and outliers (output the results regularly to ensure regular format)\n",
    "5. Plot ’GDP_growth’,’IP_growth’ and 'Unemp_rate' a a function of time and draw inferences\n",
    "\n",
    "\n",
    "A few points to note about the data:\n",
    "\n",
    "The codes and their corresponding series representation\n",
    "                        Series                   Code           Frequency\n",
    "                        Real GDP                 GDPC1          Quarterly\n",
    "                        Industrial Production   INDPRO          Quarterly\n",
    "                        Core CPI               CPILFESL         Monthly\n",
    "                        Unemployment Rate       UNRATE          Monthly\n",
    "                        10 Year Yield            GS10           Monthly\n",
    "                        1 Year Yield             GS1            Monthly\n",
    "                        Baa Yield                BAA            Monthly\n",
    "                        Aaa Yield                AAA            Monthly\n",
    "\n",
    "Variable Description\n",
    "                        Series                        Description\n",
    "                        Treated                       Dummy indicating whether the candidate received the treatment\n",
    "                        Age                           Age in years\n",
    "                        Education (years)             Years of Education\n",
    "                        Black                         Dummy indicating African-American\n",
    "                        Hispanic                      Dummy indicating Hispanic\n",
    "                        Married                       Dummy indicating married\n",
    "                        Real income Before ($)        Income before program\n",
    "                        Real income After ($)         Income after program \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import all the required packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change directory to data location\n",
    "%cd ~/Documents/DSE/dmysoren/DSE200/data/economics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## 1. Read each of the csv files iteratively\n",
    "\n",
    "# Get a list of files in the current directory\n",
    "files = !ls\n",
    "\n",
    "# Create an empty dict\n",
    "data = {}\n",
    "\n",
    "# Iterate through the file names and read into the dictionary 'data'\n",
    "for filename in files:\n",
    "    code = filename.replace('.csv','')\n",
    "    data[code] = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## 2. Merge all of the data into a single dataframe by building a dictionary where the keys are the codes \n",
    "## and the values are the Series from each downloaded file\n",
    "\n",
    "# Create an empty dict to create indexed dataframes\n",
    "data_indexed = {}\n",
    "\n",
    "# Create index on 'DATE'\n",
    "for key,value in data.iteritems():\n",
    "    data_indexed[key] = data[key].set_index('DATE')\n",
    "\n",
    "# Create merged_data with all the value columns and 'DATE' from all the datasets\n",
    "merged_data = pd.concat(data_indexed, axis = 1)\n",
    "\n",
    "## Printing the sample of merged_data\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## 3. Construct the Term and Default premia series using basic math on the series, and mmerge the resulting series using JOIN operation. \n",
    "## HINT: term_premium = merged_data[’GS10’] - merged_data[’GS1’] and default_premium = merged_data[’BAA’] - merged_data[’AAA’]\n",
    "\n",
    "term_premium = merged_data['GS10'] - merged_data['GS1'] \n",
    "default_premium = merged_data['BAA'] - merged_data['AAA']\n",
    "\n",
    "term_premium.rename(columns = {'VALUE':'term_premium'}, inplace = True)\n",
    "default_premium.rename(columns = {'VALUE':'default_premium'}, inplace = True)\n",
    "\n",
    "merged_data2 = (merged_data.join(term_premium)).join(default_premium)\n",
    "\n",
    "## Printing the sample data after merging new columns 'term_premium' and 'default_premium'\n",
    "merged_data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 4. Process the data\n",
    "## - dropping the rows with null values\n",
    "##- Output data regularly to see if they are following regular format. Use pandas.series.pct_change wherever necessary\n",
    "\n",
    "# Drop unnecessary columns and created a new data set\n",
    "merged_data3 = merged_data.drop(['AAA','BAA','GS10','GS1','CPILFESL'],axis=1)\n",
    "\n",
    "# Create a quarterly dataset by dropping NaN \n",
    "# (Although UNRATE is at a monthly level, for the purposes of analysis, only first month of the quarter is used)\n",
    "qrtly = merged_data3.dropna()\n",
    "\n",
    "# NOTE: INDRPRO is said to be quarterly data in the description (although data is populated at monthly level)\n",
    "# So Assuming that beginning of the quarter has the correct read the following approach is taken\n",
    "\n",
    "## Calculating percentage changes for GDPC1 and INDPRO\n",
    "sel_col = ['GDPC1','INDPRO']\n",
    "growth_rates = qrtly[sel_col].pct_change()\n",
    "\n",
    "## Multiplying GDPC1 and INDPRO by 100 to get percent\n",
    "growth_rates = growth_rates*100\n",
    "\n",
    "## Since Unrate is already a percentage, i'm calculating difference.\n",
    "sel_col2 = ['UNRATE']\n",
    "growth_rates2 = qrtly[sel_col2].diff()\n",
    "\n",
    "## Note: unnemployment difference is not multiplied by 100 as we need percentage point change\n",
    "\n",
    "## Create a final dataset with necessary columns which can be used to plot\n",
    "get_list = [growth_rates,growth_rates2]\n",
    "to_plot = pd.concat(get_list, axis = 1)\n",
    "\n",
    "\n",
    "# Removing the first row with NaN which is a result of pct_change and diff functions\n",
    "to_plot = to_plot.dropna()\n",
    "\n",
    "\n",
    "## 5. Plot ’GDP_growth’,’IP_growth’ and 'Unemp_rate' a a function of time and draw inferences. \n",
    "## Note: Here I have plotted all the three in separate graphs to ensure that the graph doesn't look cluttered. \n",
    "## Here, all the three graphs have their x-axes in sync so the variation in data can be read easily\n",
    "## We can use twinx to plot secondary axes if needed\n",
    "\n",
    "fig, axs = plt.subplots(3,1)\n",
    "\n",
    "(to_plot[('GDPC1','VALUE')]).plot(ax = axs[0], figsize = (15,10))\n",
    "axs[0].set_ylabel('GDP growth - % change')\n",
    "axs[0].set_xlabel('Date')\n",
    "\n",
    "(to_plot[('INDPRO','VALUE')]).plot(ax = axs[1], y = 'indpro_growth')\n",
    "axs[1].set_ylabel('Industrial production growth - % change')\n",
    "axs[1].set_xlabel('Date')\n",
    "\n",
    "to_plot[('UNRATE','VALUE')].plot(ax = axs[2], y = 'unemp_rate')\n",
    "axs[2].set_ylabel('Unemployment rate - % point change')\n",
    "axs[2].set_xlabel('Date')\n",
    "\n",
    "\n",
    "### Inference from the graphs:\n",
    "### The graphs clearly show the relationship among Unemployment rate, Industrial production and GDP growth.\n",
    "### An increase in Unemployment impacts the growth in industrial production and GDP growth.\n",
    "### Hence, maintaining a good industrial production and employment rate are crucial to maintain GDP growth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 6. Use pandas function scatter_matrix to generate scatter plots of ’GDP_growth’,’IP_growth’ and 'Unemp_rate' \n",
    "## in a mmatrix form with kernel density plots along the diagonals.\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'GDP_GROWTH':to_plot[('GDPC1','VALUE')],'IP_GROWTH':to_plot[('INDPRO','VALUE')],'UNEMP_RATE':to_plot[('UNRATE','VALUE')]})\n",
    "\n",
    "pd.scatter_matrix(df, diagonal='kde', figsize = (10,10))\n",
    "\n",
    "## The scatter matrix clearly shows the relationship between the three metrics 'GDP_Growth', 'IP_Growth' and 'Unemp_rate'\n",
    "## GDP_Growth is directly proportional to IP_growth implying GDP improves with improvemnt in industrial production\n",
    "## However, IP_growth and Unemp_rate are inversely proportional which in turn affects the GDP.\n",
    "## So, you can infer that GDP_growth is dependent on IP_growth which impacts the unemployment rates. \n",
    "## But in economics it is difficult to talk about causal and effect. Because, a poor GDP can result from an unknown factor\n",
    "## Which might in turn impact the IP_growth and unemployment rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
